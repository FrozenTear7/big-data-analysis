{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADZD L4 - Strumieniowanie\n",
    "\n",
    "## Autor: Pawe≈Ç Mendroch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .config(\"spark.sql.streaming.schemaInference\", True)\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, window, sum, avg, col, to_timestamp\n",
    "from pyspark.sql.types import StructType, TimestampType\n",
    "from pyspark.sql.streaming import DataStreamReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openaqSchema = StructType()\\\n",
    "              .add(\"city\", \"string\")\\\n",
    "              .add(\"value\", \"double\")\\\n",
    "              .add(\"local\", TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_pm25 = spark\\\n",
    "                .readStream\\\n",
    "                .format(\"sqs\")\\\n",
    "                .option(\"queueUrl\", \"<queueUrl>\")\\\n",
    "                .option(\"accessKey\", \"<accessKey>\")\\\n",
    "                .option(\"secretKey\", \"<secretKey>\")\\\n",
    "                .option(\"region\", \"us-west-1\")\\\n",
    "                .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_pm10 = spark\\\n",
    "                .readStream\\\n",
    "                .format(\"sqs\")\\\n",
    "                .option(\"queueUrl\", \"<queueUrl>\")\\\n",
    "                .option(\"accessKey\", \"<accessKey>\")\\\n",
    "                .option(\"secretKey\", \"<secretKey>\")\\\n",
    "                .option(\"region\", \"us-west-1\")\\\n",
    "                .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_avg_pm25.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_avg_pm25 = stream_pm25\\\n",
    "                    .select(\"city\", \"value\", \"date.local\")\\\n",
    "                    .withColumn(\"timestamp\", col(\"local\").cast(TimestampType()))\\\n",
    "                    .groupBy(window(\"timestamp\", \"30 minutes\", \"15 minutes\"), \"city\")\\\n",
    "                    .agg(avg(\"value\").alias(\"AVG pm25\"))\\\n",
    "                    .writeStream\\\n",
    "                    .outputMode(\"complete\")\\\n",
    "                    .format(\"console\")\\\n",
    "                    .option(\"truncate\", \"false\")\\\n",
    "                    .trigger(processingTime=\"10 seconds\")\\\n",
    "                    .start()\n",
    "\n",
    "# query_avg_pm25 = stream_pm25\\\n",
    "#                     .select(\"city\", \"value\", \"date.local\")\\\n",
    "#                     .withColumn(\"timestamp\", col(\"local\").cast(TimestampType()))\\\n",
    "#                     .withWatermark(\"timestamp\", \"15 minutes\")\\\n",
    "#                     .groupBy(window(\"timestamp\", \"30 minutes\", \"15 minutes\"), \"city\")\\\n",
    "#                     .agg(avg(\"value\").alias(\"AVG pm25\"))\\\n",
    "#                     .writeStream\\\n",
    "#                     .outputMode(\"append\")\\\n",
    "#                     .format(\"console\")\\\n",
    "#                     .option(\"truncate\", \"false\")\\\n",
    "#                     .trigger(processingTime=\"10 seconds\")\\\n",
    "#                     .start()\n",
    "\n",
    "# query_avg_pm25.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitoring_dir = \"monitor\"\n",
    "dataset_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_from_csv = spark\\\n",
    "                    .readStream\\\n",
    "                    .schema(openaqSchema)\\\n",
    "                    .csv(monitoring_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_avg_pm25_to_csv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_avg_pm25_to_csv = stream_pm25\\\n",
    "                            .select(\"city\", \"value\", \"date.local\")\\\n",
    "                            .writeStream\\\n",
    "                            .format(\"CSV\")\\\n",
    "                            .outputMode(\"append\")\\\n",
    "                            .option(\"checkpointLocation\", \"applicationHistory\")\\\n",
    "                            .option(\"path\", dataset_dir)\\\n",
    "                            .option(\"truncate\", \"false\")\\\n",
    "                            .trigger(processingTime=\"10 seconds\")\\\n",
    "                            .start()\n",
    "\n",
    "# query_avg_pm25_to_csv.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_watermark_avg_pm25.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_watermark_avg_pm25 = stream_from_csv\\\n",
    "                                .select(\"city\", \"value\", \"local\")\\\n",
    "                                .withColumn(\"timestamp\", col(\"local\").cast(TimestampType()))\\\n",
    "                                .withWatermark(\"timestamp\", \"7 days\")\\\n",
    "                                .groupBy(window(\"timestamp\", \"60 minutes\"), \"city\")\\\n",
    "                                .agg(avg(\"value\").alias(\"AVG pm25\"))\\\n",
    "                                .writeStream\\\n",
    "                                .outputMode(\"update\")\\\n",
    "                                .format(\"console\")\\\n",
    "                                .option(\"truncate\", \"false\")\\\n",
    "                                .trigger(processingTime=\"10 seconds\")\\\n",
    "                                .start()\n",
    "\n",
    "# query_avg_pm25.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "substream_pm25 = stream_pm25\\\n",
    "                    .withColumn(\"timestamp\", col(\"date.local\").cast(TimestampType()))\\\n",
    "                    .select(\"city\", \"value\", \"timestamp\", window(\"timestamp\", \"30 minutes\", \"15 minutes\"))\\\n",
    "                    .withWatermark(\"timestamp\", \"15 minutes\")\n",
    "\n",
    "substream_pm10 = stream_pm10\\\n",
    "                    .withColumn(\"timestamp\", col(\"date.local\").cast(TimestampType()))\\\n",
    "                    .select(\"city\", \"value\", \"timestamp\", window(\"timestamp\", \"30 minutes\", \"15 minutes\"))\\\n",
    "                    .withWatermark(\"timestamp\", \"15 minutes\")\n",
    "\n",
    "# .withWatermark(\"timestamp\", \"10 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_substreams = substream_pm25.alias(\"s1\")\\\n",
    "                        .join(substream_pm10.alias(\"s2\"), (col(\"s1.window\") == col(\"s2.window\")) & (col(\"s1.city\") == col(\"s2.city\")))\\\n",
    "                        .withWatermark(\"s1.timestamp\", \"15 minutes\")\\\n",
    "                        .withWatermark(\"s2.timestamp\", \"15 minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_joined_substreams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-04c1fc9b2624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_joined_substreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'query_joined_substreams' is not defined"
     ]
    }
   ],
   "source": [
    "query_joined_substreams.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Append output mode not supported when there are streaming aggregations on streaming DataFrames/DataSets without watermark;;\nAggregate [window#7774, city#6], [window#7774 AS window#7764, city#6, avg(value#2) AS AVG pm25#7771, avg(value#20) AS AVG pm10#7773]\n+- Filter ((timestamp#7546 >= window#7774.start) AND (timestamp#7546 < window#7774.end))\n   +- Expand [ArrayBuffer(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms), ArrayBuffer(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms)], [window#7774, city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms]\n      +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n         +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n            +- Project [city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms]\n               +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n                  +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n                     +- Join Inner, ((window#7558 = window#7576) AND (city#6 = city#24))\n                        :- SubqueryAlias s1\n                        :  +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n                        :     +- Project [city#6, value#2, timestamp#7546, window#7559 AS window#7558]\n                        :        +- Filter ((timestamp#7546 >= window#7559.start) AND (timestamp#7546 < window#7559.end))\n                        :           +- Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546)], [window#7559, date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546]\n                        :              +- Project [date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, cast(date#0.local as timestamp) AS timestamp#7546]\n                        :                 +- StreamingRelationV2 pl.edu.agh.SQSProvider@24ae5b53, sqs, pl.edu.agh.SQSStreamer@1d9bfbf, org.apache.spark.sql.util.CaseInsensitiveStringMap@cfddd73b, [date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8]\n                        +- SubqueryAlias s2\n                           +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n                              +- Project [city#24, value#20, timestamp#7564, window#7577 AS window#7576]\n                                 +- Filter ((timestamp#7564 >= window#7577.start) AND (timestamp#7564 < window#7577.end))\n                                    +- Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564)], [window#7577, date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564]\n                                       +- Project [date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, cast(date#18.local as timestamp) AS timestamp#7564]\n                                          +- StreamingRelationV2 pl.edu.agh.SQSProvider@53b98a64, sqs, pl.edu.agh.SQSStreamer@22c5e09, org.apache.spark.sql.util.CaseInsensitiveStringMap@cfddd75f, [date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-62aa89abe2f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery_joined_substreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoined_substreams\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s1.city\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s1.value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s2.value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s1.timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s2.timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0mwithWatermark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s1.timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"15 minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0mwithWatermark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s2.timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"15 minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                             \u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s1.timestamp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"30 minutes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"15 minutes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"s1.city\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/streaming.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, path, format, outputMode, partitionBy, queryName, **options)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueryName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueryName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Append output mode not supported when there are streaming aggregations on streaming DataFrames/DataSets without watermark;;\nAggregate [window#7774, city#6], [window#7774 AS window#7764, city#6, avg(value#2) AS AVG pm25#7771, avg(value#20) AS AVG pm10#7773]\n+- Filter ((timestamp#7546 >= window#7774.start) AND (timestamp#7546 < window#7774.end))\n   +- Expand [ArrayBuffer(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms), ArrayBuffer(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms)], [window#7774, city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms]\n      +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n         +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n            +- Project [city#6, value#2, value#20, timestamp#7546, timestamp#7564-T900000ms]\n               +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n                  +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n                     +- Join Inner, ((window#7558 = window#7576) AND (city#6 = city#24))\n                        :- SubqueryAlias s1\n                        :  +- EventTimeWatermark timestamp#7546: timestamp, 15 minutes\n                        :     +- Project [city#6, value#2, timestamp#7546, window#7559 AS window#7558]\n                        :        +- Filter ((timestamp#7546 >= window#7559.start) AND (timestamp#7546 < window#7559.end))\n                        :           +- Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7546, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546)], [window#7559, date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, timestamp#7546]\n                        :              +- Project [date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8, cast(date#0.local as timestamp) AS timestamp#7546]\n                        :                 +- StreamingRelationV2 pl.edu.agh.SQSProvider@24ae5b53, sqs, pl.edu.agh.SQSStreamer@1d9bfbf, org.apache.spark.sql.util.CaseInsensitiveStringMap@cfddd73b, [date#0, parameter#1, value#2, unit#3, averagingPeriod#4, location#5, city#6, country#7, coordinates#8]\n                        +- SubqueryAlias s2\n                           +- EventTimeWatermark timestamp#7564: timestamp, 15 minutes\n                              +- Project [city#24, value#20, timestamp#7564, window#7577 AS window#7576]\n                                 +- Filter ((timestamp#7564 >= window#7577.start) AND (timestamp#7564 < window#7577.end))\n                                    +- Expand [List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(0 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564), List(named_struct(start, precisetimestampconversion(((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0), LongType, TimestampType), end, precisetimestampconversion((((((CASE WHEN (cast(CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) as double) = (cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) THEN (CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) + cast(1 as bigint)) ELSE CEIL((cast((precisetimestampconversion(timestamp#7564, TimestampType, LongType) - 0) as double) / cast(900000000 as double))) END + cast(1 as bigint)) - cast(2 as bigint)) * 900000000) + 0) + 1800000000), LongType, TimestampType)), date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564)], [window#7577, date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, timestamp#7564]\n                                       +- Project [date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26, cast(date#18.local as timestamp) AS timestamp#7564]\n                                          +- StreamingRelationV2 pl.edu.agh.SQSProvider@53b98a64, sqs, pl.edu.agh.SQSStreamer@22c5e09, org.apache.spark.sql.util.CaseInsensitiveStringMap@cfddd75f, [date#18, parameter#19, value#20, unit#21, averagingPeriod#22, location#23, city#24, country#25, coordinates#26]\n"
     ]
    }
   ],
   "source": [
    "query_joined_substreams = joined_substreams\\\n",
    "                            .select(\"s1.city\", \"s1.value\", \"s2.value\", \"s1.timestamp\", \"s2.timestamp\")\\\n",
    "                            .withWatermark(\"s1.timestamp\", \"15 minutes\")\\\n",
    "                            .withWatermark(\"s2.timestamp\", \"15 minutes\")\\\n",
    "                            .groupBy(window(\"s1.timestamp\", \"30 minutes\", \"15 minutes\"), \"s1.city\")\\\n",
    "                            .agg(avg(\"s1.value\").alias(\"AVG pm25\"), avg(\"s2.value\").alias(\"AVG pm10\"))\\\n",
    "                            .writeStream\\\n",
    "                            .outputMode(\"append\")\\\n",
    "                            .format(\"console\")\\\n",
    "                            .option(\"truncate\", \"false\")\\\n",
    "                            .trigger(processingTime=\"10 seconds\")\\\n",
    "                            .start()\n",
    "\n",
    "# query_avg_both_substreams.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
